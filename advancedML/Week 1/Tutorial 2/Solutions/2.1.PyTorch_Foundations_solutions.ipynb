{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# PyTorch Basics\n",
    "\n",
    "Tutorial by Abdulah Fawaz and Emma R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## PyTorch Tensors\n",
    "<a id='tensors'></a>\n",
    "\n",
    "PyTorch is a lot like numpy. A lot of operations used to manipulate numpy arrays have their counterparts in pytorch and numpy arrays can be converted to and from pytorch *tensors*. PyTorch arrays are given the more proper mathematical name of tensors (see e.g tensorflow). In terms of practical usage pytorch tensors can be manipulated very similarly to NumPyâ€™s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n",
    "\n",
    "Below are some examples. Let us begin by importing torch and numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6b81e62984c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;31m#import torch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch #import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Generating a random array of size 2x2x2: NumPy vs PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Numpy\n",
    "numpy_random_arr = np.random.rand(2,2,2)\n",
    "numpy_random_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "torch_random_arr = torch.rand(2,2,2)\n",
    "torch_random_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "They are indexed in the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "torch_random_arr[0,0,0], numpy_random_arr[0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "and can be reshaped using reshape functions ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "torch_random_arr = torch_random_arr.reshape(4,2)\n",
    "print(torch_random_arr.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "numpy_random_arr = np.reshape(numpy_random_arr, [4,2])\n",
    "print(numpy_random_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Converting to and from numpy arrays is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]]) # make a numpy array\n",
    "\n",
    "a_torch = torch.from_numpy(a) #converting to a torch Tensor from a numpy array\n",
    "print(a_torch) \n",
    "\n",
    "a_np = a_torch.numpy() # converting to a numpy array from a torch Tensor\n",
    "print(a_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Other basic functions such as torch.diag, torch.cat (concatenate), torch.matmul work similarly to their numpy equivalents. <br>\n",
    "As always, when looking for a function **check the [documentation](https://stackoverflow.com/questions/25692293/inserting-a-link-to-a-webpage-in-an-ipython-notebook)** and consider running through the [official pytorch tutorial](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html) on tensor manipulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Notice that printing the torch tensor also gave a dtype. Just like in numpy, the data type of an object is important.\n",
    "PyTorch Tensors types - just like in any other programming language - depend on whether they are storing integers, floating points or bools, and in how many bits. Often, it is important to make sure tensors are of the right / matching type when performing operations on them.\n",
    "<br>\n",
    "See https://pytorch.org/docs/stable/tensors.html for a list of dtypes and what they are called in PyTorch.\n",
    "\n",
    "Changing torch tensor type is simple too:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(a_torch)\n",
    "print(a_torch.to(torch.double)) #casts the int32 dtype tensor into a 64 bit float dtype tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Tensor reshaping/resizing can be completed using torch.view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "x = torch.randn(3, 3)\n",
    "\n",
    "y = x.view(1, -1)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "## Exercise 1. Basic Tensor Operations\n",
    "\n",
    "There is some streamlining of operations in pytorch relative to numpy which can simplify code development. For example, compare here the multiplications of two arrrays using broadcasting.\n",
    "\n",
    "1. Generate two random numpy arrays, **a** and __b__ of sizes [12,5] and [3,5,20] \n",
    "\n",
    "\n",
    "2. Find the matrix product **a** $\\cdot$ __b__ using broadcasting. The result should be of shape (3,12,20) <br>\n",
    "    *hint: may need to reshape a first*\n",
    "    \n",
    "    \n",
    "3. Convert **a** and __b__ into PyTorch Tensors and perform direct multiplication (without reshaping).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "a = np.random.rand(12,5)\n",
    "b = np.random.rand(3,5,20)\n",
    "np.matmul(np.reshape(a, [1, 12,5]),b).shape\n",
    "\n",
    "a_t = torch.from_numpy(a)\n",
    "b_t = torch.from_numpy(b)\n",
    "\n",
    "print(torch.matmul(a_t, b_t).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Autograd: automatic differentiation\n",
    "\n",
    "As you might imagine, it is not the similarities between the two that we are interested in, but what makes torch Tensors relevant to machine learning. The most significant and relevant difference is that PyTorch Tensors also have an associated *gradient*. It is this that is used to perform the optimization that machine learning is based on. \n",
    "\n",
    "The gradient of a pytorch tensor is stored as its ```.grad``` attribute. All pytorch tensors have this even if it is not apparent nor used. In such a case it would be set to \"None\". \n",
    "\n",
    "All PyTorch tensors have another boolean attribute ```requires_grad``` that indicates whether pytorch *needs* to track and store its gradient or whether it is simply a static tensor. By default, requires_grad is set to False.\n",
    "When we later construct neural networks from the torch.nn neural network module, requires_grad will be automatically set to True for the relevant learning parameters so it is not something you should generally worry about setting manually.\n",
    "\n",
    "In addition the attribute ```grad_fn```: This is the backward function used to calculate the gradient.\n",
    "\n",
    "For example, let's observe gradient estimation for a simple function $L = \\frac{1}{N} \\sum_{i}\\sum_j (2x_{ij}+3)^2  $ operating on a matrix $\\mathbf{X}$ with $N$ elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "X = torch.ones(5,5, requires_grad=True) # generate a random Tensor\n",
    "\n",
    "print(X.grad) # check its gradient - the result is None\n",
    "\n",
    "y=2*X+3\n",
    "z=y*y\n",
    "out = z.mean()\n",
    "\n",
    "\n",
    "out.backward()\n",
    "print(X.grad) \n",
    "print(out.grad_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Exercise2  prove this is correct using the chain rule.\n",
    "\n",
    "Do this now and then try repeating the process for another simple function, of your choice. Try also generating $\\mathbf{X}$ in different ways, suign torch random number generators for example.\n",
    "\n",
    "**Note** PyTorch only supports gradient estimation for can only be calculated for floating point tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "In pratice the ```autograd``` package provides an engine to perform backpropagation. As variables and operations are defined it sets up a dynamic computational graph in the same sense as we saw in our first lecture. In this, the leaves of the graph are input tensors, defined using initialisation operations such as those shown [above](#tensors), and identified using the attribute ```is_leaf==True```. Roots are output tensors. Gradients are then calculated by tracing the graph from the root to the leaf and multiplying every gradient in the way using the chain rule. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## PyTorch NN Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "The torch.nn module contains all the functions you will need to build a neural network. \n",
    "<br> This includes fully connected layers, convolutions, and pooling operations. \n",
    "\n",
    "\n",
    "It is well documented and easy to read: **See for Yourself** https://pytorch.org/docs/stable/nn.html\n",
    "\n",
    "We will go over a few nn modules and then use what we have learned to build an MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Let us begin with a 2d Convolution: one of the most common and important functions used in image processing and deep learning in general. We will be generating a *single* 3D 'image' example (array of 3 input channels, 100 x 100 pixels) and performing a 2d Convolution with stride = 1, kernel size = 3x3 and 2 output channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# the first dimension has size N where N is the number of images. \n",
    "#here it is simply 1\n",
    "\n",
    "input_image = torch.randint(0, 255, (1, 3,100,100)) # our random image. \n",
    "\n",
    "# building our conv operation. note that we did not need to specify the names of the parameters. \n",
    "#nn.Conv2d(3,2,3) is sufficient\n",
    "operation = nn.Conv2d(in_channels = 3,out_channels = 2, kernel_size = 3) \n",
    "\n",
    "print(operation) #we can see our convolution operation by printing it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "First try the following operation - observe the ```RuntimeError```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "result = operation(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "The operation fails as it cannot work on integer tensors. Let us convert it into a float tensor first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "input_image = input_image.to(torch.float)\n",
    "result = operation(input_image)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Observe the shape of the ```result``` with respect to the shape of the original image. We see we lose a unit around the edge of the 2D image and the output number of features reduce from 3 to 2 as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(result.shape,input_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "We can correct this using padding, as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-93027c6a73a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moperation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_channels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout_channels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0minput_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "operation = nn.Conv2d(in_channels = 3,out_channels = 2, kernel_size = 3, padding=1)\n",
    "input_image = input_image.to(torch.float)\n",
    "result = operation(input_image)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "The result shows the result of a 2d Convolution between our image and some randomly generated kernel. What if we wanted to inspect that kernel? We can use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "for name, param in operation.named_parameters(): # for each named parameter\n",
    "    print(name, param.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Above we can see that our convolution weight tensor is of shape [2,3,3,3] (2 $3\\times 3\\times 3$ convoltuional filters) and has a bias of shape [2].\n",
    "\n",
    "We can do the same for a fully connected Linear layer, which can be found in the torch.nn module under the function Linear(). Its parameters are the number of input features and the number of output features.\n",
    "We will use 3x100x100 = 300000 input features and 10 output features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "fc_operation = nn.Linear(30000, 10) # defining our fully connected Linear layer\n",
    "\n",
    "reshaped_input_image = input_image.reshape(input_image.size(0), -1) #reshaping input image \n",
    "\n",
    "print('input image shape ', input_image.shape,'reshaped_input_image shape' , reshaped_input_image.shape)\n",
    "result = fc_operation(reshaped_input_image) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "The goal with the reshape operation is to unravel the image into a single vector. As you may be accustomed with in numpy, reshape dimensions of (input_image.size(0), -1) reshape the image into a vector, where -1 tells pytorch to, essentially, figure out itself what should be the corresponding size of this dimension given the input. \n",
    "\n",
    "Note, input_image.size(0) returns the size of the first dimension of our image array, which represents the number of examples. Here, it is one but in real examples, there can be a variable number of images used in each batch. By defining the first dimension of the reshape size(0) it ensures that we unravel each image independently, to return an $N \\times 300000$ array: ```reshaped_input_image```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Functional\n",
    "\n",
    "As you will see as we go forward most PyTorch layers can be implemented either as a `torch.nn.Module` object or as a `torch.nn.Functional` function. So which should you use? \n",
    "\n",
    "Essentially,  `nn.functional` provides building block functions (e.g. layers / activations) in form of functions. This means that they can be directly called on the input rather than defining the object. \n",
    "\n",
    "In cases, where we have weights or other states which might define the behaviour of the layer (for example, a dropout / Batch Norm layer behaves differently during training and inference) a convolutional layer where we need to keep track of the weights over time, then we should use `nn.Module` objects. The whle points is that these define a class to hold the data structure, and make (e.g. convolutional) operations member functions.\n",
    "\n",
    "On the other hand, in cases where no state or weights are required, `nn.functional` counterparts may be used. Examples being, resizing (nn.functional.interpolate),  average pooling (nn.functional.AvgPool2d) and activation functions.\n",
    "\n",
    "For more details see https://blog.paperspace.com/pytorch-101-advanced/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Max pooling\n",
    "\n",
    "The maxpool function in pytorch is [```nn.MaxPool2d```](https://pytorch.org/docs/stable/nn.html?highlight=maxpool#torch.nn.MaxPool2d). As we have seen in our lectures the max pool operation downsamples an image by selecting the maximum intensity of an image patch to represent the whole patch.\n",
    "\n",
    "### Exercise 3: MaxPooling in 2D.\n",
    "\n",
    "Generate a random integer array to represent 5 images which have 3 channels are of size (100 x 100). Perform a 2D maxpool on the images using PyTorch. Your max pooling operation should have:\n",
    "\n",
    "1. filter size 3x3, stride = 1 x 1\n",
    "\n",
    "2. filter size 4 x 2, stride = 2 x 2\n",
    "\n",
    "**Hint** check the docs (linked above)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#solution\n",
    "\n",
    "random_ims = torch.randint(0, 255, (5,3,100,100)).to(torch.float)\n",
    "\n",
    "maxpoolop = nn.MaxPool2d(3,1) \n",
    "print(maxpoolop)\n",
    "r = maxpoolop(random_ims)\n",
    "print(r.shape)\n",
    "\n",
    "\n",
    "maxpoolop = nn.MaxPool2d((4,2),2) \n",
    "print(maxpoolop)\n",
    "r = maxpoolop(random_ims)\n",
    "print(r.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Data Loading\n",
    "\n",
    "In Deep Learning, the data must be collected and prepared into batches before being fed into the neural network for training. In many cases, our medical imaging data is too large to be all loaded into memory at once. We may also want to transform (augment) our data either as a pre-processing step or to simulate the creation of bigger data sets. Typically we want to randomly shuffle our data during training such that our network does not always see data in the same order. Pytorch streamlines this process through the provision of two classes: *DataSet*, and accompanying iterator *DataLoader*.\n",
    "\n",
    "For common datasets such as MNIST and CIFAR10 Pytorch provides default `DataSets` https://pytorch.org/docs/stable/torchvision/datasets.html. However, for more bespoke applications it is necessary to create tailored `DataSet` classes which inherit from the base class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset and DataLoader Class\n",
    "\n",
    "Let's look at the basic structure of the `Dataset` class (https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataset.py) and discuss some of it's optional features. \n",
    "\n",
    "`class Dataset(object):  \n",
    "    \"\"\"An abstract class representing a :class:Dataset.\n",
    "    All datasets that represent a map from keys to data samples should subclass\n",
    "    it. All subclasses should overwrite :meth:__getitem__, supporting fetching a\n",
    "    data sample for a given key. Subclasses could also optionally overwrite\n",
    "    :meth:__len__/, which is expected to return the size of the dataset by many\n",
    "    :class:~torch.utils.data.Sampler implementations and the default options\n",
    "    of :class:~torch.utils.data.DataLoader.\n",
    "    .. note::\n",
    "      :class:~torch.utils.data.DataLoader by default constructs a index\n",
    "      sampler that yields integral indices.  To make it work with a map-style\n",
    "      dataset with non-integral indices/keys, a custom sampler must be provided.\n",
    "    \"\"\" \n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "    def __add__(self, other):\n",
    "        return ConcatDataset([self, other])`\n",
    "\n",
    "What this states is that any class that inherits from the baseclass must override the following methods:\n",
    "\n",
    "- `__len__` so that len(dataset) returns the size of the dataset.\n",
    "- `__getitem__` which returns a sample from the dataset given an index. For supervised learning from images this requires it to return both an example image and its label.\n",
    "\n",
    "In addition to this it is common to pass a transform argument to the `DataSet` class which will support augmentation of the data. After that you have great freedom as to the actual structure and ordering of the code in the class. \n",
    "\n",
    "The `DataLoader` is an iterator class, which uses the `__getitem__` and `__len__` functions to collate data into batches and sample at random (`shuffle`) from the data referenced by the `Dataset` class. It also supports loading and processing the data in parallel (with the number of parallel processes determined by parameter `num_workers`. **Generally shuffling the order of the data is very important** as, in this way, the batches between epochs will not look alike, improving generalisation.\n",
    "\n",
    "The generic form of a call to `DataLoader` is \n",
    "\n",
    "`dataloader = DataLoader(transformed_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)`\n",
    "                        \n",
    "Unlike the `Dataset` class this is unlikely to need overloading.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Loading MNIST from torchvision\n",
    "\n",
    "Let's start by looking at how to use custom PyTorch datasets available through `torchvision.`\n",
    "\n",
    "The torchvision package consists of popular datasets, model architectures, and common image transformations for performing computer vision tasks.\n",
    "\n",
    "Let us use it to load the MNIST data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "MNIST is found under datasets.MNIST. The class supports direct download of the data from the internet as indicated by the `download` argument. It is necessary to define a target directory for the download as `root`. Data is also already separated into `train` and `test` subsets. For further help understanding the class datasets.MNIST, use $\\text{datasets.MNIST.__doc __}$ to view the documentation or view https://pytorch.org/docs/stable/torchvision/datasets.html#mnist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(datasets.MNIST.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "There are many potential transformations that are supported through `torchvision` and can be performed to the image (such as rotations, crops, flips, etc). The use of these is controlled by the `transform` argument of the `Dataset` class. Here, however, we will only apply a transformation to turn the PIL format image into a torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "mnist_train_dataset = datasets.MNIST(root = 'mnist_data/train', download= True, train = True,\n",
    "                                     transform = transforms.ToTensor())\n",
    "mnist_test_dataset = datasets.MNIST(root = 'mnist_data/test', download= True, train = False, \n",
    "                                    transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "To explore the shape of the data set we must used the overloaded class function ```len()``` to determine the number of examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(len(mnist_train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "In this case, as MNIST is an image classfication data set. Each individual item is a tuple, representing the data and its integer label i.e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(type(mnist_train_dataset[0]))\n",
    "ex_train_image, ex_train_label=mnist_train_dataset[0]\n",
    "                                                   \n",
    "print('Image shape',ex_train_image.shape,'label',ex_train_label,type(ex_train_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "We can visualise the data using matplotlibs `imshow` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(ex_train_image[0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Thus, we see that mnist_train_dataset contains 60k 28x28 images of hand-written numbers, with labels (the integer numbers from 0-9), in torch tensor format.\n",
    "\n",
    "To use this data for deep learning, we can then load both test and train sets onto dataloaders, which dispatch batches and shuffle the data for us as:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "       mnist_train_dataset, batch_size= 128, shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "       mnist_test_dataset, batch_size = 128, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Shuffling is not required for test data.\n",
    "\n",
    "Now that we have our dataloaders, we can simply iterate through them with the inbuilt iter() function.\n",
    "<br>\n",
    "To view just one batch instead of the entire data, we use apply the next() function on the iterator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "im_batch, lab_batch=next(iter(train_loader)) # view one batch\n",
    "\n",
    "print(len(im_batch),im_batch[0].shape,lab_batch[0])\n",
    "plt.imshow(im_batch[0,0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "This returns one batch -  a tuple of images and labels. By looking at the image batch we can see N (first column) is 128 - the size of the batch. Image dminesions are $1 \\times 28 \\times 28$ as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Loading custom data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "The process for loading a customised dataset is not so far from the process above, except that we need to define our own dataset class. \n",
    "\n",
    "\n",
    "This class only needs two defined functions. One that provides the `len()` of the dataset, the other called `getitem` that outputs one data pair given an index.\n",
    "\n",
    "*How* this is done is up to you. The method we go over is only a suggestion. However you choose to do it, `getitem` must, given an index, output the data and its appropriate label, corresponding to that index. This is because the DataLoader class will call this function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "In this example, we will use an example of image segmentation from computer vision, with a dataset which contains photos of scences accompanied by their semantic segmentations. Thus the label is now an image of size equal to that of the data.\n",
    "\n",
    "\n",
    "We will read the images and segmentation masks from the ```sample_dataset_tutorial``` folder downloaded with your tutorial. Since they are .png files, we will need to import the imageio module to allow us to load them from this format. We will also need to import os to access the folders and directories in the computer via python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "class OurCustomDataSet(torch.utils.data.Dataset): #we create a class that inherits the torch Dataset abstract class \n",
    "    \n",
    "    def __init__(self, data_folder_location): # initialise the class based on the folder containing the data\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        First look at the folder containing the data. It is structured in two folders.\n",
    "        There are images in an 'images' folder, and masks in a 'segmentations' folder. \n",
    "        We need to match these up together and correctly.\n",
    "        \n",
    "        \n",
    "        \n",
    "        First we define the root folder and extract the images and segmentations subfolders \n",
    "        containing the data (images) and the labels (segmentations).\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.data_folder_location = data_folder_location\n",
    "        \n",
    "        self.images_folder = data_folder_location + '/images'\n",
    "        \n",
    "        self.labels_folder = data_folder_location + '/segmentations'\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        Now we use os.listdir() to get a list of the files within the subfolders. \n",
    "        \n",
    "        We sort both these lists to make sure that the image files' titles and \n",
    "        the segmentation files' titles match. \n",
    "        \n",
    "        They are titled in such a way to allow this to work by simply sorting. \n",
    "        \n",
    "        (Other data might require more a more complex matching process.\n",
    "        e.g. you might construct a dictionary matching image title to mask title)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.images_list_sorted = os.listdir(self.images_folder)\n",
    "        self.images_list_sorted.sort()\n",
    "        \n",
    "        self.labels_list_sorted = os.listdir(self.labels_folder)\n",
    "        self.labels_list_sorted.sort()\n",
    "\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def __len__(self):\n",
    "        # this returns the length of the dataset. It is usually simple to code\n",
    "        \n",
    "        return len(os.listdir(self.images_folder))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        getitem should pull the idx'th image and its associated segmentation and output them together as a sample\n",
    "        \n",
    "        we begin by indexing the list of image and label //titles// \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        image_name = self.images_list_sorted[idx] # this is the idx'th image\n",
    "        \n",
    "        label_name = self.labels_list_sorted[idx] # this is the idx'th segmentation  # THEY SHOULD MATCH\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        Now we have to load the png files given these titles. \n",
    "        \n",
    "        We first find their exact locations and then load them using imageio\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        full_image_location = str(self.images_folder)+'/' + str(image_name)\n",
    "        \n",
    "        full_label_location = str(self.labels_folder) + '/' + str(label_name)\n",
    "        \n",
    "        image = imageio.imread(full_image_location)\n",
    "        \n",
    "        label = imageio.imread(full_label_location)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        Before we output, they are currently in .png format. So we need to turn them into torch Tensors\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        image = transforms.ToTensor()(image)\n",
    "        label = transforms.ToTensor()(label)\n",
    "             \n",
    "        sample = image, label\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Now to try out our custom dataset.  Edit the below path so that it matches where you have placed your data. \n",
    "\n",
    "**Note** if you're using Google Colab you will need to load the data to your google drive and edit the path accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "directory = '../Data/sample_dataset_tutorial/'  # we define the directory of the data\n",
    "\n",
    "ds = OurCustomDataSet(directory) # then we create the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ds.__len__() # check if the length is correct. We can see from the folders there are 18 items in total\n",
    "             # we should get the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Now lets try to pull out a sample. Lets try the first one.\n",
    "\n",
    "example_im,ex_label=ds.__getitem__(0)\n",
    "print(type(example_im),example_im.shape,ex_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "It worked! It returned two torch tensors, one labeled 'image' the other labeled 'label'.\n",
    "\n",
    "\n",
    "If you are wish to be extra sure that they match, we can plot them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "im, lab = OurCustomDataSet(directory).__getitem__(14) # im , lab are our image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "transforms.ToPILImage()(im) # quickly converting back to PIL image to view it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "transforms.ToPILImage()(lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "We are done! At this point we simply need to load our dataset into the dataloader as usual and the dataloader will provide batches for our deep learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "loaded_data = DataLoader(ds, batch_size = 2, shuffle = False)\n",
    "\n",
    "im_batch, lab_batch = next(iter(loaded_data)) # get a batch\n",
    "print(im_batch.shape) # we get [2,3,1500,200] which we expect since the \n",
    "                      # images are [3 x 1500 x 2500] and the batch size is 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Exercise 4: Create a  custom data Loader for medical data\n",
    "\n",
    "In this exercise we will create a custom data loader to load medical imaging data, and medical segmentations or phenotypic label data.\n",
    "\n",
    "The data that we will use can be found in folder `dHCP_brain_data` and conatins 3D brain volumes, tissue segmentations and a pickled dataframe (`dHCP_demographics.pkl`) containing phenotypes including the infants age at birth ('birth_ga'), age at scan ('scan_ga') and gender ('gender'). Individual images can be identified by their subject 'id' (starting 'CC00') and the `session` of the scan (e.g. '7201'). This is reflected in filenames starting (for example) `sub-CC00050XX01_ses-7201` with files:\n",
    "1. sub-CC00050XX01_ses-7201_T2w_restore_brain.nii.gz a T2-weighted structural image of each neonates brain\n",
    "2. sub-CC00050XX01_ses-7201_drawem_tissue_labels.nii.gz a semantic segmentation of tissues in the brain, including labels for cortical and subcortical grey matter, white matter and cerebral spinal fluid (CSF). For the full list of labels see https://github.com/MIRTK/DrawEM/blob/master/label_names/tissue_labels_LUT_ITKSNAP.txt\n",
    "\n",
    "For context, the image files look as \n",
    "\n",
    "<img src=\"brain_volumes.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "And can be viewed individually using 3D nifti image viewers such as FSLeyes https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSLeyes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### 4.1 Create a data loader for brain images and their segmentations\n",
    "\n",
    "In the first task, as for the computer vision example we will create a dataloader to load brain images and their segmentations.\n",
    "\n",
    "First we need a module that will load medical image volumes (here niftii images .nii.gz). There are several options including `SimpleITK`. Here, we use `nibabel`.\n",
    "\n",
    "**Note** you will need to edit the paths throughout so that they match where you have put your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel\n",
    "\n",
    "image_file=nibabel.load('../Data/dHCP_brain_data/sub-CC00050XX01_ses-7201_T2w_restore_brain.nii.gz')\n",
    "segmentation_file=nibabel.load('../Data/dHCP_brain_data/sub-CC00050XX01_ses-7201_drawem_tissue_labels.nii.gz')\n",
    "\n",
    "img=image_file.get_fdata().astype(np.float)\n",
    "seg=segmentation_file.get_fdata().astype(np.int32)\n",
    "print(img.shape,seg.shape)\n",
    "print(type(img),type(seg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, loading data in this way returns a numpy array. Thus converting to a torch tensor is straightforward as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = torch.from_numpy(img).to(torch.float)\n",
    "seg_tensor=torch.from_numpy(seg).to(torch.float)\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `imshow` to view one central slice of the image and it's segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_tensor.shape)\n",
    "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True,\n",
    "                       figsize=(8, 4))\n",
    "ax[0].imshow(img_tensor[:,:,120], cmap=plt.cm.gray)\n",
    "ax[0].set_title('T2 image - axial slice')\n",
    "ax[1].imshow(seg_tensor[:,:,120], cmap=plt.cm.Dark2)\n",
    "ax[1].set_title('Tissue segmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as we are dealing with 3D volumesn we need to reshape our images into the form, which they are expected by Pytorch `conv3D` $C\\times D \\times H \\times W $, where $C$=channels (here 1), $D$=depth, $H$=height and $W$ = width (https://pytorch.org/docs/master/nn.html#torch.nn.Conv3d). \n",
    "\n",
    "Hence, we need to bring our re-order the spatial dimensions of our tensor, using Pytorch `permute`0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor=img_tensor.permute(2,0,1)\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And add a fourth dimension for channels. This can be done using the PyTorch `unsqueeze` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor=img_tensor.unsqueeze(0)\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need a way of returning the paths of the data from an index. We could put images and segmentations into different folders (as above) and sort but this could feasibly lead to difficult to track down bugs. Let us instead use the project dataframe instead, using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "meta=pd.read_pickle('../Data/dHCP_brain_data/dHCP_demographics.pkl')\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image file can thus be defined through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_sample=meta.iloc[0]\n",
    "img_path=os.path.join('../Data/dHCP_brain_data','sub-' + str(meta_sample['id']) +'_ses-' + str(meta_sample['session']) +'_T2w_restore_brain.nii.gz')\n",
    "\n",
    "img_sample=nibabel.load(img_path)\n",
    "\n",
    "print(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To do** Putting this all together, use these functions to create your own data loader for pairs of brain imaging data and clinical segmentations in the following steps\n",
    "\n",
    "1.  complete the class constructor - used to initialise class variables: folder (path to data folder), meta (the dataframe) and transform\n",
    "2. Complete the overloaded __len(self)__ class, to return the number of data examples\n",
    "In `__getitem__`:\n",
    "3.  return the paths to the image and the segmentation file\n",
    "4. load the images\n",
    "5. Convert to tensors and reshape to expected dimensions\n",
    "\n",
    "**hint** consider also looking to https://pytorch.org/tutorials/beginner/data_loading_tutorial.html for guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# students create own data loader\n",
    "\n",
    "#we create a class that inherits the torch Dataset abstract class \n",
    "class BrainSegmentationDataset(torch.utils.data.Dataset): \n",
    "    \n",
    "    # initialise the class based on the folder containing the data and the project dataframe\n",
    "    def __init__(self, folder='', meta='',transform=None): \n",
    "        \n",
    "       # 2.1.1 initialise the paths to the data folder, the data frame and define the transform operations\n",
    "        self.folder = folder\n",
    "        self.meta = pd.read_pickle(meta)\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "         # 2.1.2 return the number of examples in the dataset\n",
    "        return len(self.meta)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \n",
    "        # 2.1.3 return the paths to the image and the segmentation file \n",
    "        meta_sample=self.meta.iloc[idx] #Â this will return the idx-th row from the dataframe\n",
    "        image_name = os.path.join(self.folder,'sub-' + str(meta_sample['id']) +'_ses-' + \n",
    "                                  str(meta_sample['session']) +'_T2w_restore_brain.nii.gz')  # this is the idx'th image   \n",
    "        label_name = os.path.join(self.folder,'sub-' + str(meta_sample['id']) +'_ses-' \n",
    "                                  + str(meta_sample['session']) +'_T2w_restore_brain.nii.gz')  # this is the idx'th segmentation  # THEY SHOULD MATCH\n",
    "        \n",
    "        # 2.1.4 load images \n",
    "        image=nibabel.load(image_name)\n",
    "        label=nibabel.load(image_name)\n",
    "        \n",
    "        # 2.1.5 Convert to tensors and reshape to expected dimensions\n",
    "        img_tensor = torch.from_numpy(img).to(torch.float)\n",
    "        seg_tensor=torch.from_numpy(seg).to(torch.float)\n",
    "        \n",
    "        img_tensor=img_tensor.permute(2,0,1)\n",
    "        seg_tensor=seg_tensor.permute(2,0,1)\n",
    "        \n",
    "        img_tensor=img_tensor.unsqueeze(0)\n",
    "        seg_tensor=seg_tensor.unsqueeze(0)\n",
    "        \n",
    "        # convert to  tuple and return\n",
    "        sample = img_tensor, seg_tensor\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To Do now try out your custom data** through:\n",
    "\n",
    "1. Instantiate an instance of the BrainSegmentationDataset class by calling the constructor\n",
    "2. check that the length is correct\n",
    "3. return index 0 from getitem, \n",
    "4. plot the 120th axial slice of the returned img and segmentation. Be sure your segmentation matches your image  **Hint** remember that we have permuted the order of our slices and added a dimension for channels\n",
    "5. Create a class iterator using DataLoader and create a batch of size 3, print the shape of the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#2.2.1 Inistantiate an instance of the BrainSegmentationDataset class by calling the constructor\n",
    "directory = '../data/dHCP_brain_data'  # we define the directory of the data\n",
    "meta='../data/dHCP_brain_data/dHCP_demographics.pkl'\n",
    "ds = BrainSegmentationDataset(directory,meta) # then we create the dataset \n",
    "\n",
    "#2.2.2 check that the length is correct\n",
    "print(ds.__len__())\n",
    "\n",
    "#2.2.3 return index 0 from getitem\n",
    "example_im,ex_label=ds.__getitem__(0)\n",
    "print(type(example_im),example_im.shape,ex_label.shape)\n",
    "\n",
    "#2.2.4 plot the 120th axial slice \n",
    "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True,\n",
    "                       figsize=(8, 4))\n",
    "ax[0].imshow(example_im[0,120,:,:], cmap=plt.cm.gray)\n",
    "ax[0].set_title('T2 image - axial slice')\n",
    "ax[1].imshow(ex_label[0,120,:,:], cmap=plt.cm.Dark2)\n",
    "ax[1].set_title('Tissue segmentation')\n",
    "\n",
    "#2.2.5 Create a class iterator using DataLoader and create a batch of size 3\n",
    "loaded_data = DataLoader(ds, batch_size = 3, shuffle = False)\n",
    "\n",
    "im_batch, lab_batch = next(iter(loaded_data)) # get a batch\n",
    "print('batch shape', im_batch.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Finally, using this example, repeat the process but this time for a classification task. I.e. rather than returning a semantic tissue segmentation instead create a data loaded for which the label is the neonataes age at scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-763116ea5ba4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# students create own data loader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mBrainAgeRegressionDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# students create own data loader\n",
    "\n",
    "class BrainAgeRegressionDataset(torch.utils.data.Dataset): \n",
    "    \n",
    "    def __init__(self, folder='', meta='',label='',transform=None): \n",
    "        \n",
    "       # 2.1.1 initialise the paths to the data folder, the data frame and define the transform operations\n",
    "        self.folder = folder\n",
    "        self.meta = pd.read_pickle(meta)\n",
    "        self.label=label\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "         # 2.1.2 return the number of examples in the dataset\n",
    "        return len(self.meta)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \n",
    "        # load image,  Convert to tensors and reshape to expected dimensions\n",
    "        meta_sample=self.meta.iloc[idx] #Â this will return the idx-th row from the dataframe\n",
    "        image_name = os.path.join(self.folder,'sub-' + str(meta_sample['id']) +'_ses-' + \n",
    "                                  str(meta_sample['session']) +'_T2w_restore_brain.nii.gz')  # this is the idx'th image   \n",
    "        \n",
    "        image=nibabel.load(image_name)\n",
    "        \n",
    "        img_tensor = torch.from_numpy(img).to(torch.float)\n",
    "        img_tensor=img_tensor.permute(2,0,1)        \n",
    "        img_tensor=img_tensor.unsqueeze(0)\n",
    "        \n",
    "        # read in label and convert to pytorch \n",
    "        label = torch.from_numpy(np.asarray(meta_sample[self.label])).to(torch.float)\n",
    "\n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(img_tensor)\n",
    "        \n",
    "        # convert to  tuple and return\n",
    "        sample = img_tensor, label\n",
    "\n",
    " \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2.1 Instantiate \n",
    "directory = '../data/dHCP_brain_data'  # we define the directory of the data\n",
    "meta='../data/dHCP_brain_data/dHCP_demographics.pkl'\n",
    "label='scan_ga'\n",
    "ds = BrainAgeRegressionDataset(directory,meta,label) # then we create the dataset \n",
    "\n",
    "#2.2.2 check that the length is correct\n",
    "print(ds.__len__())\n",
    "\n",
    "#2.2.3 return index 0 from getitem\n",
    "example_im,ex_label=ds.__getitem__(0)\n",
    "print(type(example_im),example_im.shape,ex_label)\n",
    "\n",
    "loaded_data = DataLoader(ds, batch_size = 3, shuffle = False)\n",
    "\n",
    "im_batch, lab_batch = next(iter(loaded_data)) # get a batch\n",
    "print('batch shape', im_batch.shape,lab_batch) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "## References\n",
    "\n",
    "For more reading on this topic see the official PyTorch tutorials https://pytorch.org/tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
