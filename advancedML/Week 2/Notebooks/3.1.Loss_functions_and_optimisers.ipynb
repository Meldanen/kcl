{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3, Notebook 1: Optimisers and Loss Functions\n",
    "\n",
    "Tutorial by Mark Graham\n",
    "\n",
    "## Optimisers\n",
    "### Exercise 1.1 Gradient descent\n",
    "In this section we'll dig into optimisers in more detail. So far, we have considered simple gradient descent. In gradient descent, the update rule is :\n",
    "\n",
    "$$ \\mathbf{W}_{t+1} = \\mathbf{W}_{t}  - \\eta \\left.\\dfrac{\\partial L}{\\partial \\mathbf{W}}\\right|_{w_{t}} $$\n",
    "\n",
    "where $L$ is our loss function, $\\mathbf{W}$ our parameters and $\\eta$ our learning rate.\n",
    "\n",
    "Let's implement gradient descent. \n",
    "Consider the following loss function for a simple two-parameter system:\n",
    "\n",
    "$$ L = 40w_1^2 + 10 w_2^2 + 40 w_2$$\n",
    "\n",
    "#### 1.1.1 Implement the loss function in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# the loss function\n",
    "def loss(w1, w2):\n",
    "    #### STUDENT'S ANSWER HERE ####\n",
    "    # Answer\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Because our loss function is simple, we were able to calculate its minimum analytically.\n",
    "\n",
    "#### 1.1.2 estimate the analytic mimina of a convex function\n",
    "\n",
    "Implement the function below which returns the partial derivatives $\\dfrac{\\partial L}{\\partial w_1}$ and $\\dfrac{\\partial L}{\\partial w_2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient(w1,w2):\n",
    "    #### STUDENT'S ANSWER HERE ####\n",
    "    # Answer:\n",
    "    grad_w1 = None\n",
    "    grad_w2 = None\n",
    "    return (grad_w1, grad_w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3. estimate the coordinates of the minima\n",
    "\n",
    "Use your calculation above to estimate the coordinates of the minima  $ w_{1min},w_{2min}, L_{min}$ and plug into the `plot_surface` function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "# generate evenly spaced values \n",
    "w1 = np.linspace(-5, 5, 30)\n",
    "w2 = np.linspace(-5, 5, 30)\n",
    "W1, W2 = np.meshgrid(w1, w2)\n",
    "# compute value of loss function for each parameter combination\n",
    "losses = loss(W1, W2)\n",
    "#### STUDENT'S ANSWER HERE ####\n",
    "w_1min=None\n",
    "w_2min=None\n",
    "L_min=None\n",
    "\n",
    "# plot\n",
    "def plot_surface(W1,W2,loss_coords,minima):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.contour3D(W1, W2, losses, 50, cmap='binary')\n",
    "    ax.set_xlabel('w1')\n",
    "    ax.set_ylabel('w2')\n",
    "    ax.set_zlabel('loss');\n",
    "    # plot the minimum\n",
    "    ax.scatter3D(minima[0], minima[1], minima[2], loss_coords,c='green',s = 100)\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "fig, ax = plot_surface(W1, W2, losses,[w_1min,w_2min,L_min])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need a way of updating our parameters, making use of the gradient. \n",
    "\n",
    "#### 1.1.4 Implement the gradient descent update rule below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gradient_descent():\n",
    "    def __init__(self, learning_rate):\n",
    "        # we can store parameters of the descent algorithm here.\n",
    "        self.lr = learning_rate\n",
    "\n",
    "    def __call__(self, w1, w2, w1_grad, w2_grad):\n",
    "        # our actual computation happens here.\n",
    "        #### STUDENT'S ANSWER HERE ####\n",
    "        # Answer:\n",
    "        w1_updated = None\n",
    "        w2_updated = None\n",
    "\n",
    "        return w1_updated, w2_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to perform gradient descent. Run the following cell, which calls your functions `loss_gradient` and `gradient_descent`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coords(w1_coords, w2_coords, loss_coords, axis):\n",
    "    ax.plot3D(w1_coords,w2_coords,loss_coords,c='red')\n",
    "    ax.scatter3D(w1_coords,w2_coords,loss_coords,c='red',s=100)\n",
    "    ax.set_xlim(-5,5)\n",
    "    ax.set_ylim(-5,5);\n",
    "    ax.set_zlim(-100,1500)\n",
    "\n",
    "# starting point\n",
    "w1 = -4\n",
    "w2 = 4\n",
    "\n",
    "num_epochs = 100\n",
    "lr = 0.01\n",
    "# create our optimiser here\n",
    "grad_descent = gradient_descent(learning_rate=lr)\n",
    "\n",
    "# create empty lists to hold the coordinates\n",
    "w1_coords, w2_coords, loss_coords = [], [], []\n",
    "for epoch in range(num_epochs):\n",
    "    w1_coords.append(w1)\n",
    "    w2_coords.append(w2)\n",
    "    Loss=loss(w1,w2)\n",
    "    loss_coords.append(Loss)\n",
    "    w1_grad, w2_grad =  calculate_gradient(w1,w2)\n",
    "    w1, w2 = grad_descent(w1, w2, w1_grad, w2_grad)\n",
    "\n",
    "    if (abs(w1_grad) > 0.01) or (abs(w2_grad) > 0.01):\n",
    "        print('epoch {} , loss {:.3f}, w1 gradient: {:.3f} w2 gradient: {:.3f}'.format(epoch,Loss,w1_grad, w2_grad))\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# do the plotting\n",
    "fig, ax = plot_surface(W1, W2, losses,[w_1min,w_2min,L_min])\n",
    "plot_coords(w1_coords, w2_coords, loss_coords, ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should work pretty well. Lets investigate some things:\n",
    "- How sensitive is our solution to the learning rate? Try out different values in the above cell, both larger and smaller. What do you notice?\n",
    "- Estimate how long it takes for out solution to converge, by altering the number of epochs at a fixed lr=0.003\n",
    "\n",
    "### Exercise 1.2: Gradient descent with momentum\n",
    "Momentum adds 'memory' to our gradient descent, averaging the gradient at the current step with gradients from previous steps. The update equations gradient descent with momentum are:\n",
    "\n",
    "$$ \\mathbf{z}_{t+1} = \\beta   \\mathbf{z}_{t} +  \\eta \\left.\\dfrac{\\partial L}{\\partial \\mathbf{W}}\\right|_{\\mathbf{W}_{t}} \\\\\n",
    "\\mathbf{W}_{t+1} = \\mathbf{W}_{t}  -  \\mathbf{z}_{t+1} $$\n",
    "\n",
    "where $\\beta$ is the momentum parameter and $\\eta$ the learning rate. \n",
    "\n",
    "#### 1.2.1 Implement the momentum update in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gradient_descent_momentum():\n",
    "    def __init__(self, momentum, learning_rate):\n",
    "        # as well as the parameters momentum and lr, we need to store z_1 and z_2 between update steps.\n",
    "        self.momentum = momentum\n",
    "        self.lr = learning_rate\n",
    "        self.z_1 = 0\n",
    "        self.z_2 = 0\n",
    "        \n",
    "    def __call__(self, w1, w2, w1_grad, w2_grad):\n",
    "        ### STUDENT CODE HERE####\n",
    "        # Answer:\n",
    "        self.z_1 = None\n",
    "        self.z_2 = None\n",
    "        w1_updated = w1 - self.z_1\n",
    "        w2_updated = w2 -  self.z_2\n",
    "        return w1_updated, w2_updated    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below calls the momentum update. Run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting point\n",
    "w1 = -4\n",
    "w2 = 4\n",
    "\n",
    "num_epochs = 100\n",
    "lr = 0.003\n",
    "momentum = 0.6\n",
    "gradient_descent_mom = gradient_descent_momentum(momentum=momentum, learning_rate=lr)\n",
    "\n",
    "# create empty lists to hold the coordinates\n",
    "w1_coords, w2_coords, loss_coords = [], [], []\n",
    "for epoch in range(num_epochs):\n",
    "    w1_coords.append(w1)\n",
    "    w2_coords.append(w2)\n",
    "    Loss=loss(w1,w2)\n",
    "    loss_coords.append(Loss)\n",
    "    w1_grad, w2_grad =  calculate_gradient(w1,w2)\n",
    "    w1, w2 = gradient_descent_mom(w1,w2, w1_grad, w2_grad)\n",
    "    if (abs(w1_grad) > 0.01) or (abs(w2_grad) > 0.01):\n",
    "        print('epoch {} , loss {:.3f}, w1 gradient: {:.3f} w2 gradient: {:.3f}'.format(epoch,Loss,w1_grad, w2_grad))\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# do the plotting\n",
    "fig, ax = plot_surface(W1, W2, losses,[w_1min,w_2min,L_min])\n",
    "plot_coords(w1_coords, w2_coords, loss_coords, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now play with the momentum parameters:\n",
    "1. What do you notice about the convergence speed of momentum compared to gradient descent? \n",
    "2. Vary the learning rate. What do you notice about higher learning rates, compared to gradient descent?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3: RMSProp\n",
    "RMSProp also keeps a 'memory', but here it uses this memory to moderate the learning rate for each parameter independently, so that smaller steps are taken in directions with larger gradients. The update equations are:\n",
    "\n",
    "$$ \\mathbf{v}_{t+1} = \\beta   \\mathbf{v}_{t} +  (1-\\beta) \\left( \\left.\\dfrac{\\partial L}{\\partial \\mathbf{W}}\\right|_{w_{t}}\\right)^2 \\\\\n",
    "\\mathbf{W}_{t+1} = \\mathbf{W}_{t}  - \\dfrac{\\eta}{\\sqrt{\\mathbf{v}_{t+1} + \\epsilon}} \\circ  \\left.\\dfrac{\\partial L}{\\partial \\mathbf{W}}\\right|_{w_{t}} $$\n",
    "\n",
    "The update looks complicated, but compare with the gradient descent update. They're the same, except the learning rate $\\eta$ is divided by a scalar that is calculated at each update step. \n",
    "\n",
    "#### 1.3.1. Implement this update step below.\n",
    "\n",
    "As we have only 2 features, implement the updates for each feature separately by:\n",
    "\n",
    "- estimating `self.v1` and `self.v2` correspending to $\\mathbf{v}_{t+1}$ for each parameter. This implements an exponential average of the square of the gradient with respect to each parameter\n",
    "- estimate `lr_1` and `lr_2` the learning rate correction ($\\dfrac{\\eta}{\\sqrt{\\mathbf{v}_{t+1} + \\epsilon}}$) for each parameter \n",
    "- update weights for each parameter (`w1_updated`, `w2_updated`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSProp():\n",
    "    def __init__(self, momentum, learning_rate):\n",
    "        self.momentum = momentum\n",
    "        self.lr = learning_rate\n",
    "        self.v_1 = 0\n",
    "        self.v_2 = 0\n",
    "        self.epsilon = 1e-5\n",
    "        \n",
    "    def __call__(self, w1, w2, w1_grad, w2_grad):\n",
    "        ### STUDENT CODE HERE####\n",
    "        # Answer:\n",
    "        self.v_1 = None\n",
    "        self.v_2 = None\n",
    "        lr_1 = None\n",
    "        lr_2 = None\n",
    "        \n",
    "        w1_updated = None\n",
    "        w2_updated = None\n",
    "        return w1_updated, w2_updated    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use RMSProp - run the cell below, which calls your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting point\n",
    "w1 = -4\n",
    "w2 = 4\n",
    "\n",
    "num_epochs = 30\n",
    "lr = 0.5\n",
    "momentum = 0.9\n",
    "rmsprop = RMSProp(momentum=momentum, learning_rate=lr)\n",
    "\n",
    "# create empty lists to hold the coordinates\n",
    "w1_coords, w2_coords, loss_coords = [], [], []\n",
    "for epoch in range(num_epochs):\n",
    "    w1_coords.append(w1)\n",
    "    w2_coords.append(w2)\n",
    "    Loss=loss(w1,w2)\n",
    "    loss_coords.append(Loss)\n",
    "    w1_grad, w2_grad =  calculate_gradient(w1,w2)\n",
    "    w1, w2 = rmsprop(w1,w2, w1_grad, w2_grad)\n",
    "    if (abs(w1_grad) > 0.01) or (abs(w2_grad) > 0.01):\n",
    "        print('epoch {} , loss {:.3f}, w1 gradient: {:.3f} w2 gradient: {:.3f}'.format(epoch,Loss,w1_grad, w2_grad))\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# do the plotting\n",
    "fig, ax = plot_surface(W1, W2, losses,[w_1min,w_2min,L_min])\n",
    "plot_coords(w1_coords, w2_coords, loss_coords, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the learning rate and momentum. What do you notice about the learning rate needed compared to previous update rules? What about the speed of convergence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent\n",
    "\n",
    "In order to investigate optimisers here, we've been analysing a simple, quadratic loss function with parameters that are known to us. This made it straightforward to calculate both the loss and its gradient for any set of parameters, $w_1,w_2$. However, in a practical ML application we won't have this nice functional form for the loss. For a simple two parameter regression problem, the loss would take the form:\n",
    "\n",
    "$$ L = \\sum_{i=1}^{N } (y_i - x_{1i}w_1 - x_{2i}w_2)^2$$\n",
    "\n",
    "We can see the loss will still be quadratic in our two parameters $w_1,w_2$ but will depend on our $N$ training data points $\\{\\mathbf{x_i}, y_i\\}$. At each iteration we will need to run our model over the full dataset to calculate the loss and gradient. Recall that we did this when we trained our MLP on the preterm dataset in lecture 1.\n",
    "\n",
    "If $N$ is very large, or we have a large model with lots of parameters (e.g. a neural network) it can be time-consuming and memory-intensive to run through the full dataset to get the gradients for our next parameter updates. In practice, we calculate the loss and gradients for a randomly chosen subset of the data at each iteration, approximating the loss and the gradients at that point. This has the effect of giving us noisy gradient updates - we don't necessarily take the optimal step at each iteration, but sometimes this can help us avoid/jump out of local minima.\n",
    "\n",
    "### Exercise 4: Stochastic gradient descent for real data\n",
    "\n",
    "Let's repeat our training loop from lecture 1, this time using SGD.\n",
    "\n",
    "First let's create custon Dataset and Dataloader class for our brain data. Here, any preprocessing to be run on the whole data set should be run _only once_, and thus should go in the `__init__` function. \n",
    "\n",
    "**1.4.1 Complete the `__len__` and `__getitem__` methods** \n",
    "Check that the class returns the number of items and feature bvector lengths that you expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "epsilon=1e-5\n",
    "\n",
    "class PretermDataset(Dataset):\n",
    "    # init loads the data in exactly the same way we did in lecture 1\n",
    "    def __init__(self):     \n",
    "        # Read the data\n",
    "        df = pd.read_pickle(\"prem_vs_termwrois.pkl\")\n",
    "        data = df.values[:,:-2]\n",
    "        y = df.values[:,-1]\n",
    "\n",
    "\n",
    "        # Create feature matrix\n",
    "        X = data.T\n",
    "        bias_row=np.ones((1,X.shape[1]))\n",
    "        X = np.concatenate((np.ones((1,X.shape[1])),X))\n",
    "        \n",
    "        # centre X\n",
    "        X_centred = np.ones_like(X)\n",
    "        X_centred[1:] = (X[1:] -X[1:].mean(axis=1,keepdims=True)) / (X[1:].std(axis=1,keepdims=True)+epsilon)\n",
    "        # store X and y in the class so they can be accessed by other functions\n",
    "        self.X = X_centred\n",
    "        self.y =  y\n",
    "    \n",
    "    def __len__(self):\n",
    "        # STUDENTS COMPLETE\n",
    "        return None\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # STUDENTS COMPLETE\n",
    "        sample=None\n",
    "        return sample\n",
    "\n",
    "dataset = PretermDataset()\n",
    "print('Number of entries in dataset: {}'.format(len(dataset)))\n",
    "x, y = dataset[5]\n",
    "print('Shape of one item in x: {}'.format(x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4.2 create a dataloader to iterate through your class**\n",
    "\n",
    "Initially set `batch_size` to equal the total number of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENTS COMPLETE\n",
    "batch_size = None\n",
    "dataloader = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 Double check you understand what the training loop (below) is doing\n",
    "See where the code has been changed to allow for variable batch sizes (using a dataloader)\n",
    "\n",
    "### 1.4.4 Investigate the influence of batch size \n",
    "The code below recreates the MLP training we implemented in lecture 1, except at every iteration it loops through all the batches in the dataloader. \n",
    "\n",
    "1. For a batch size = N, (in this case N=101) we have gradient descent and the training curves should look similar to the training curves in lecture 1. Verify this is the case.\n",
    "2. Reduce the batch size to implement stochastic gradient descent - what do you notice about the training curves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epsilon = 1e-5\n",
    "\n",
    "# initialise w1, w2\n",
    "W1 = np.random.randn(5,301)\n",
    "W2 = np.random.randn(1,5)\n",
    "\n",
    "# we'll store the loss and accuracy in these lists during training\n",
    "loss_record_mlp = []\n",
    "accuracy_record_mlp = []\n",
    "\n",
    "num_iterations = 40\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def relu(x):\n",
    "    # Answer\n",
    "    return x * (x>=0)\n",
    "\n",
    "def f(z):\n",
    "    return 1 / (1+ np.exp(-z))\n",
    "\n",
    "\n",
    "def loss(y, y_pred):\n",
    "    epsilon = 1e-5\n",
    "    # note the negative sign so that the loss decreases as our predictions get better\n",
    "    # we must add a small penaty term to prevent calculation of log(0)\n",
    "    L = - y * np.log(y_pred+epsilon) - (1-y) * np.log(1-y_pred+epsilon) \n",
    "    J = np.mean(L)\n",
    "    return J\n",
    "\n",
    "def accuracy(y, y_pred, threshold = 0.5):\n",
    "    y_pred_thresholded = y_pred > threshold\n",
    "    correct_predictions = np.sum(y==y_pred_thresholded)  \n",
    "    total_predictions = np.shape(y)\n",
    "    accuracy = 100 * correct_predictions / total_predictions\n",
    "    return accuracy\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    # forward pass - get predictions\n",
    "    for X_centred, y in dataloader:\n",
    "        X_centred = X_centred.T.numpy()\n",
    "        y = y.numpy()\n",
    "        # answer\n",
    "        Z1 = np.matmul(W1,X_centred)\n",
    "        F1 = relu(Z1)\n",
    "        Z2 = np.matmul(W2,F1)\n",
    "        F2 = f(Z2) # recall f is the sigmoid function\n",
    "        l = loss(y,F2) \n",
    "\n",
    "        # store the loss/ accuracy at this iteration\n",
    "        loss_record_mlp.append(l)\n",
    "        accuracy_record_mlp.append(accuracy(y,F2))\n",
    "\n",
    "\n",
    "        #backwards pass to get gradients\n",
    "        dL_dW2=np.matmul(F2-y,F1.T) \n",
    "        dL_dF1=np.matmul(W2.T,F2-y)      \n",
    "        dF2_dZ1  = 1.0 *(Z1> 0)\n",
    "\n",
    "\n",
    "        dL_dZ1=np.multiply(dL_dF1,dF2_dZ1)\n",
    "        dL_dW1 = np.matmul(dL_dZ1,X_centred.T)\n",
    "        dJ_dW2=(1/W2.shape[0])*dL_dW2 \n",
    "        dJ_dW1=(1/W1.shape[0])*dL_dW1 \n",
    "\n",
    "        # update the weights\n",
    "        W2 = W2 - learning_rate * dJ_dW2    \n",
    "        W1 = W1 - learning_rate * dJ_dW1\n",
    "        \n",
    "# plot loss and accuracy    \n",
    "print('Training with a batch size of {}'.format(batch_size))\n",
    "fig, ax = plt.subplots(1,2, figsize = (18,5))\n",
    "ax[0].plot(loss_record_mlp)\n",
    "ax[1].plot(accuracy_record_mlp)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions\n",
    "\n",
    "### Exercise 5: Generalised dice overlap\n",
    "The GDL can be used for multiclass segmentation - the full paper is [here](https://arxiv.org/pdf/1707.03237.pdf). Let's implement it.\n",
    "\n",
    "First lets load in the data: a T1 image, segmented into 7 classes. We have both a ground truth label and a label predicted by a partially trained neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= np.load('images.npz')\n",
    "image = file['arr_0']\n",
    "ground_truth = file['arr_1']\n",
    "pred = file['arr_2']\n",
    "labels = {0: 'Background',\n",
    "          1: 'CSF',\n",
    "          2: 'Basal Ganglia',\n",
    "          3: 'Cortex',\n",
    "          4: 'Brainstem',\n",
    "          5: 'Cerebellum',\n",
    "          6 : 'White matter'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to plot the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "rgb_values = sns.color_palette(\"Set3\", 7)\n",
    "cmap = colors.ListedColormap(rgb_values, N=7)\n",
    "custom_lines = [Line2D([0], [0], color=rgb_values[i], lw=4) for i in range(7)]\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(image,cmap='gray'); plt.axis('off'); plt.title('Image')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(ground_truth,cmap=cmap, vmin=0, vmax=6); plt.axis('off');plt.title('Ground Truth');\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(pred,cmap=cmap, vmin=0, vmax=6); plt.axis('off'); plt.title('Prediction');\n",
    "plt.legend(custom_lines, labels.values(),loc='best', fontsize = 'medium');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GDL can be expressed as \n",
    "\n",
    "$$\n",
    "\\mathrm{GDL}=1-2 \\frac{\\sum_{l=1}^{2} w_{l} \\sum_{n} y_{l n} \\hat{y}_{l n}}{\\sum_{l=1}^{2} w_{l} \\sum_{n}( y_{l n}+\\hat{y}_{l n})}\n",
    "$$\n",
    "\n",
    "where $y$ is the true segmentation map, $\\hat{y}$ the predicted class label, $w_l$ is a weight for each class; subscript $l$ refers to the class, and $n$ each pixel in the image. The class weight is estimated from \n",
    "$$1 /\\left(\\sum_{n=1}^{N} y_{l n}\\right)^{2}$$ \n",
    "Which gives higher weight to classes with fewer examples.\n",
    "\n",
    "The first stage is to one-hot encode the segmentation maps, transforming them from a $WxH$ array to a $CxWxH$ array where each channel contains a binary segmentation mask for each class.\n",
    "\n",
    "### 1.5.1 Implement a function to one hot encode the segmentation maps\n",
    "\n",
    "You will need to loop over all classes and, for each class $i$,  create a binary segmentation (of dimensions equal to the original image) with values 1 (where voxel belongs to class $i$) and 0 (where it does not)\n",
    "\n",
    "**Hint** you may want to use numpy masking i.e. Nonhttps://www.python-course.eu/numpy_masking.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(mask, num_classes):\n",
    "    #### STUDENT CODE HERE####\n",
    "    # Answer\n",
    "    mask_encoded = None\n",
    "    for i in range(num_classes):\n",
    "        mask_encoded[i,:,:] = None\n",
    "    return mask_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the encoding makes sense. Run the following cell to one-hot encode and plot each class seperately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_encoded = one_hot_encode(ground_truth, num_classes=7)\n",
    "prediction_encoded = one_hot_encode(pred, num_classes=7)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "for i in range(7):\n",
    "    plt.subplot(2,7,i+1)\n",
    "    plt.imshow(ground_truth_encoded[i,:,:]); plt.axis('off')\n",
    "    plt.title(labels[i])\n",
    "    plt.subplot(2,7,i+8)\n",
    "    plt.imshow(prediction_encoded[i,:,:]); plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2.  Implement the GDL: \n",
    "\n",
    "The function can be implemented without looping over all voxels, provided you make use of numpy vectorisation, complete the below function to estimate\n",
    "- the numerator $\\sum_{l=1}^{2} w_{l} \\sum_{n} y_{l n} \\hat{y}_{l n}$\n",
    "- the denominator $\\sum_{l=1}^{2} w_{l} \\sum_{n}( y_{l n}+\\hat{y}_{l n})$\n",
    "- the complete GDL \n",
    "\n",
    "We suggest a correction for division by zero by setting `weight=epsilon` in these circumstances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gdl(truth, prediction):\n",
    "    \n",
    "    epsilon=1e-5\n",
    "    num_classes = truth.shape[0]\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    \n",
    "    #### STUDENT CODE HERE ####\n",
    "    # Answer   \n",
    "    for l in range(num_classes):\n",
    "        weight  = None\n",
    "        if np.isinf(weight):\n",
    "            weight = epsilon\n",
    "        numerator += None\n",
    "        denominator += None\n",
    "        \n",
    "    GDL=None\n",
    "        \n",
    "    return GDL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the loss value for our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdl(ground_truth_encoded, prediction_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And sanity check: do we get a loss of 0 when our ground truth and prediction exactly match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "gdl(ground_truth_encoded, ground_truth_encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
